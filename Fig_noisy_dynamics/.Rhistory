mapping = aes(x = mu, y = abs(x_reduced - R)/max(R, x_reduced), fill = as.factor(n_patch)),
color = 'transparent',
fun.min = function(z) { quantile(z,0.25) },
fun.max = function(z) { quantile(z,0.75) },
fun = median,
geom = 'ribbon', alpha = 0.3) +
stat_summary(
mapping = aes(x = mu, y = abs(x_reduced - R)/max(R, x_reduced), color = as.factor(n_patch)),
fun = median,
geom = 'line') +
facet_grid(k_sd~kind) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_sd, y = x_reduced_sd, shape = kind, color = kind)) +
geom_point() +
xlim(c(0, 10)) +
ylim(c(0, 10)) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_mean, y = x_reduced_mean, shape = kind, color = kind)) +
geom_point() +
theme_bw()
ggplot(data = data_melted, mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist), shape = as.factor(noise_cov_dist))) +
geom_point(alpha = 0.5) +
facet_grid(Metric ~ kind) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, fill = as.factor(noise_cov_dist)),
color = 'transparent',
fun.min = function(z) { quantile(z,0.25) },
fun.max = function(z) { quantile(z,0.75) },
fun = median,
geom = 'ribbon', alpha = 0.3) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, fill = as.factor(noise_cov_dist)),
fun = median,
geom = 'line') +
theme_bw()
data[data$sd_RAE == max(data$sd_RAE)]
data[data$sd_RAE == max(data$sd_RAE),]
# a script that tests the one-dimensional spectral reduction over a list of networks
# sources and libraries ####################################################################
rm(list = ls())
library(deSolve)
library(igraph)
library(parallel)
library(stats)
# functions for the reduction
source("../one_dimension_spectral_reduction.R")
# functions for dynamics
source("../Dynamics/metapop_dynamics.R")
source("../Dynamics/Growth_functions.R")
source("../Dynamics/Dispersal_functions.R")
source("../Networks/Network_functions.R")
# creating output directories ###############################################################
dir.create("output")
# declaring fixed parameters ######################################################################
# demographic properties
r = 1
baseline_K = 30
c = 0 # allee effect threshold == 0 --> the model is just a logistic growth
k_sd = 0.15
mu = -1
# timestep for the stochastic integration
dt = 0.01
network_id = 'RGG_1'
print(network_id)
t = seq(0, 1000, 1) # time seq for integration
network = read_network(paste0("Network_list/", network_id))
print(network_id)
source("~/Documents/These/Chapter_dimension_reduction/Scripts/Fig_noisy_dynamics/Simulations.R", echo=TRUE)
# a script that tests the one-dimensional spectral reduction over a list of networks
# sources and libraries ####################################################################
rm(list = ls())
library(deSolve)
library(igraph)
library(parallel)
library(stats)
# functions for the reduction
source("../one_dimension_spectral_reduction.R")
# functions for dynamics
source("../Dynamics/metapop_dynamics.R")
source("../Dynamics/Growth_functions.R")
source("../Dynamics/Dispersal_functions.R")
source("../Networks/Network_functions.R")
# creating output directories ###############################################################
dir.create("output")
# declaring fixed parameters ######################################################################
# demographic properties
r = 1
baseline_K = 30
c = 0 # allee effect threshold == 0 --> the model is just a logistic growth
k_sd = 0.15
mu = -1
# timestep for the stochastic integration
dt = 0.01
network_id = 'RGG_9'
print(network_id)
t = seq(0, 1000, 1) # time seq for integration
network = read_network(paste0("Network_list/", network_id))
disp_matrix = network$dispersal_matrix
n_patch = ncol(disp_matrix)
data = data.frame(network_id = '',
kind = network$summary$kind,
rep = 0,
noise_amplitude = 0,
noise_cov_dist = 0,
# odsr parameters
alpha = 0,
alpha.out = 0,
beta = 0,
odsr.cov = 0,
eigen.ratio = 0, # ratio of the first two eigen values
R_init = 0, # reduction of the initial state
# averages of the time series
R_mean = 0, # predicted reduction
x_bar_mean = 0, # average equilibrium
x_reduced_mean = 0, # reduced eq
# sd-dev of the time series
R_sd = 0,
x_bar_sd = 0,
x_reduced_sd = 0,
# acf lag 1 of time series
R_acf_1 = 0,
x_bar_acf_1 = 0,
x_reduced_acf_1 = 0)
x_init = rnorm(n_patch, baseline_K, 0.1*baseline_K)
K_vect = rnorm(n_patch, baseline_K, baseline_K * k_sd)
rep = 1
noise_amplitude = 0.01
dist_cov = 0.05
network$cov_matrix = make_cov_matrix(network, dist_cov)*noise_amplitude # making a cov matrix of correlation distance dist_cov
network$summary$covariance_distance = dist_cov
network$cov_matrix
network$cov_matrix = make_cov_matrix(network, dist_cov)*noise_amplitude # making a cov matrix of correlation distance dist_cov
network$summary$covariance_distance = dist_cov
W = disp_matrix*10^mu # scaling the disp_matrix by mu
odsr.object = odsr(W, type = 'stochastic', cov_matrix = network$cov_matrix) # computing the one dimensional spectral reduction
if (Re(odsr.object$alpha) < 0 ){
odsr.object = odsr(W, type = 'stochastic', cov_matrix = network$cov_matrix, n_eig = 2)
}
odsr.object$a = sapply(odsr.object$a, Re)
odsr.object$alpha = Re(odsr.object$alpha)
odsr.object$alpha.out = Re(odsr.object$alpha.out)
odsr.object$beta = Re(odsr.object$beta)
odsr.object$cov = Re(odsr.object$cov)
par = list(r = 1,
K = K_vect,
c = 0)
out = ode(y = x_init,
times = t,
func = metapop_dynamics_stochastic,
parms = par,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
W = W,
Cov = network$cov_matrix/dt,
method = "euler",
hini = dt)
plot(out)
plot(out[800:1000,])
plot(out[800:1000,:])
plot(out[800:1000,])
plot(out[800:1000,2:42])
plot(out[800:1000,2:22])
plot(out[800:1000,1])
plot(out[800:1000,2])
plot(out[800:1000,2], type = 'l')
plot(out[800:1000,3], type = 'l')
plot(out[800:1000,4], type = 'l')
plot(out[950:1000,4], type = 'l')
plot(out[950:1000,5], type = 'l')
plot(out[950:1000,6], type = 'l')
odsr.out = odsr.dynamics(times = t,
x = x_init,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
odsr.object = odsr.object,
par = par,
dt = dt)
## computing metrics for the 500 last timesteps of the dynamics:
# extracting the last 500 timesteps
out = out[500:nrow(out),2:ncol(out)]
osdr.out = odsr.out[500:nrow(odsr.out), 2]
#making x_bar and x_reduced time series:
x_bar = rowMeans(out)
x_reduced = out %*% odsr.object$a
# averages of the time series
R_mean = mean(osdr.out) # predicted reduction
plot(osdr.out)
plot(osdr.out, type = 'l')
plot(x_bar type = 'l')
plot(x_bar, type = 'l')
sd(x_bar)
sd(odsr.out)
sd(odsr.out[, 2])
osdr.out
sd(odsr.out)
odsr.out
odsr.out
odsr.out = odsr.dynamics(times = t,
x = x_init,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
odsr.object = odsr.object,
par = par,
dt = dt)
## computing metrics for the 500 last timesteps of the dynamics:
# extracting the last 500 timesteps
out = out[500:nrow(out),2:ncol(out)]
osdr.out = odsr.out[500:nrow(odsr.out), 2]
odsr.out
odsr.out[2]
odsr.out[,2]
x_bar
head(x_bar)
odsr.out = odsr.dynamics(times = t,
x = x_init,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
odsr.object = odsr.object,
par = par,
dt = dt)
odsr.out[500:nrow(odsr.out), 2]
R = odsr.out[500:nrow(odsr.out), 2]
R
out = ode(y = x_init,
times = t,
func = metapop_dynamics_stochastic,
parms = par,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
W = W,
Cov = network$cov_matrix/dt,
method = "euler",
hini = dt)
odsr.out = odsr.dynamics(times = t,
x = x_init,
growth_function = logistic_allee,
dispersal_function = linear_dispersal,
odsr.object = odsr.object,
par = par,
dt = dt)
## computing metrics for the 500 last timesteps of the dynamics:
# extracting the last 500 timesteps
x = out[500:nrow(out),2:ncol(out)]
R = odsr.out[500:nrow(odsr.out), 2]
#making x_bar and x_reduced time series:
x_bar = rowMeans(x)
x_reduced = x %*% odsr.object$a
# averages of the time series
R_mean = mean(R) # predicted reduction
x_bar_mean = mean(x_bar) # average equilibrium
x_reduced_mean = mean(x_reduced) # reduced eq
# sd-dev of the time series
R_sd = sd(R)
x_bar_sd = sd(x_bar)
x_reduced_sd = sd(x_reduced)
R_sd
x_reduced_sd
abs(R_sd - x_reduced_sd)/max(R_sd, x_reduced_sd)
plot(osdr.out[950:100,])
plot(osdr.out[950:100])
plot(osdr.out[950:100], type = 'l')
plot(osdr.out[950:1000], type = 'l')
odsr.out
plot(odsr.out[odsr.out$time > 950])
plot(odsr.out[950:1000])
plot(odsr.out[950:1000, 2])
plot(odsr.out[950:1000, 2], type = 'l')
plot(x_reduced[950:1000], type = 'l')
plot(x_reduced[950:1000,], type = 'l')
x_reduced
plot(x_reduced[450:,])
plot(x_reduced[450:])
plot(x_reduced[450:500])
plot(x_reduced[450:500], type = 'l')
plot(x_reduced[450:500], type = 'l', ylim = c(25, 35))
points(R[450:500], type = 'l', color = 'red')
points(R[450:500], type = 'l', col = 'red')
plot(x_reduced[450:500], type = 'l', ylim = c(25, 35))
points(R[450:500], type = 'l', col = 'red')
# generating networks
# sources and libraries ##############################################################
rm(list = ls())
library(igraph)
# functions for dynamics
source("../Networks/Network_functions.R")
# creating folders ###################################################################
dir.create("Network_list", recursive = T)
# Generating networks ################################################################
n_patch_list = c(21) # landscape sizes
n_landscapes = 10 # number of landscapes of each size
connectivity = 5 # connectivity for RGGs and erdos-renyi
# generating networks
# sources and libraries ##############################################################
rm(list = ls())
library(igraph)
# functions for dynamics
source("../Networks/Network_functions.R")
# creating folders ###################################################################
dir.create("Network_list", recursive = T)
# Generating networks ################################################################
n_patch_list = c(21) # landscape sizes
n_landscapes = 10 # number of landscapes of each size
connectivity = 5 # connectivity for RGGs and erdos-renyi
## generating erdos_renyi networks #################################################################
id = 1
for (n_patch in n_patch_list){
for(k in 1:n_landscapes){
print(paste0('ER  ', id))
network = make_erdos_renyi(n_patch)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
while (is_connected(graph_from_adjacency_matrix(network$dispersal_matrix > 0)) != T){
network = make_erdos_renyi(n_patch)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
}
write_network(network, paste0('Network_list/ER_', id))
id = id+1
}
}
## generating erdos_renyi networks #################################################################
id = 1
for (n_patch in n_patch_list){
for(k in 1:n_landscapes){
print(paste0('ER  ', id))
network = make_erdos_renyi(n_patch, c = connectivity)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
while (is_connected(graph_from_adjacency_matrix(network$dispersal_matrix > 0)) != T){
network = make_erdos_renyi(n_patch, c = connectivity)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
}
write_network(network, paste0('Network_list/ER_', id))
id = id+1
}
}
make_erdos_renyi = function(n_patch, c, covariance_distance = 0){
# creates an erdos-renyi network with 'n_patch' patches and an average connectivity of 'c'
# note that this function returns a distance matrix and a variance-covariance matrix
# for consistency with the other landscape-generating functions, but the points have
# no real position so the distance matrix is a dummy and the covariance matrix
# with 0 outside the diagonal
# the points_coords are taken from igraph plotting and do not reflect real positions but are useful for plotting.
network = list()
network$summary = data.frame(kind = 'Erdos-Renyi', n_patch = n_patch, covariance_distance = 0)
# making a dummy distance matrix:
distance_matrix = matrix(rep(NaN, n_patch**2), nrow = n_patch)
# Making an adjacency matrix and checking that it is connected
adjacency_matrix = erdos_renyi_adj(n_patch, c)
while (is_connected(graph_from_adjacency_matrix(adjacency_matrix)) != T){
adjacency_matrix = erdos_renyi_adj(n_patch, c)
}
## drawing some random positions (unrelated to the network connectivity)
network$points_coords = draw_positions(n_patch)$points_coords
# getting the distance matrix
network$distance_matrix = make_distance_matrix(network$points_coords)
# getting the adjacency matrix
network$adjacency_matrix = adjacency_matrix
# getting the dispersal matrix
network$dispersal_matrix = make_dispersal_matrix(network$adjacency_matrix)
# getting the covariance matrix
network$cov_matrix = make_cov_matrix(network, covariance_distance)
return(network)
}
## generating erdos_renyi networks #################################################################
id = 1
for (n_patch in n_patch_list){
for(k in 1:n_landscapes){
print(paste0('ER  ', id))
network = make_erdos_renyi(n_patch, c = connectivity)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
while (is_connected(graph_from_adjacency_matrix(network$dispersal_matrix > 0)) != T){
network = make_erdos_renyi(n_patch, c = connectivity)
network$dispersal_matrix = randomize_link_strength(network$dispersal_matrix, 0.2)
}
write_network(network, paste0('Network_list/ER_', id))
id = id+1
}
}
library(ggplot2)
library(reshape2)
data = read.csv('output/0_All_data.csv', header = T)
# computing the relative absolute error of mean, sd and acf_1
data$mean_RAE = abs(data$x_reduced_mean - data$R_mean)/pmax(data$R_mean, data$x_reduced_mean)
data$sd_RAE = abs(data$x_reduced_sd - data$R_sd)/pmax(data$R_sd, data$x_reduced_sd)
data$acf_1_RAE = abs(data$x_reduced_acf_1 - data$R_acf_1)/pmax(abs(data$R_acf_1), abs(data$x_reduced_acf_1))
data_melted = melt(data,
measure.vars = c("mean_RAE", "sd_RAE", "acf_1_RAE"),
variable.name = 'Metric',
value.name = 'Relative_absolute_error')
metric.lab = c('Mean', 'Standard deviation', 'Autocorrelation lag 1')
names(metric.lab) = c('mean_RAE', 'sd_RAE', 'acf_1_RAE')
ggplot(data = data_melted, mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist), shape = as.factor(noise_cov_dist))) +
geom_point(alpha = 0.5) +
facet_grid(Metric ~ kind, labeller = labeller(Metric = metric.lab)) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, fill = as.factor(noise_cov_dist)),
color = 'transparent',
fun.min = function(z) { quantile(z,0.25) },
fun.max = function(z) { quantile(z,0.75) },
fun = median,
geom = 'ribbon', alpha = 0.3) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist)),
fun = median,
geom = 'line') +
scale_color_discrete('Spatial autocorrelation of noise') +
scale_fill_discrete('Spatial autocorrelation of noise') +
scale_shape_discrete('Spatial autocorrelation of noise') +
xlab('Noise amplitude') +
ylab('Relative absoulte error') +
theme_bw() +
theme(legend.position = 'bottom')
# some verification of the bias by plotting predicted vs. observed
ggplot(data = data, mapping = aes(x = R_mean, y = x_reduced_mean, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(25, 30)) +
ylim(c(25, 30)) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_sd, y = x_reduced_sd, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(0, 6)) +
ylim(c(0, 6)) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_acf_1, y = x_reduced_acf_1, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(0, 1)) +
ylim(c(0, 1)) +
theme_bw()
library(ggplot2)
library(reshape2)
data = read.csv('output/0_All_data.csv', header = T)
# computing the relative absolute error of mean, sd and acf_1
data$mean_RAE = abs(data$x_reduced_mean - data$R_mean)/pmax(data$R_mean, data$x_reduced_mean)
data$sd_RAE = abs(data$x_reduced_sd - data$R_sd)/pmax(data$R_sd, data$x_reduced_sd)
data$acf_1_RAE = abs(data$x_reduced_acf_1 - data$R_acf_1)/pmax(abs(data$R_acf_1), abs(data$x_reduced_acf_1))
data_melted = melt(data,
measure.vars = c("mean_RAE", "sd_RAE", "acf_1_RAE"),
variable.name = 'Metric',
value.name = 'Relative_absolute_error')
metric.lab = c('Mean', 'Standard deviation', 'Autocorrelation lag 1')
names(metric.lab) = c('mean_RAE', 'sd_RAE', 'acf_1_RAE')
ggplot(data = data_melted, mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist), shape = as.factor(noise_cov_dist))) +
geom_point(alpha = 0.5) +
facet_grid(Metric ~ kind, labeller = labeller(Metric = metric.lab)) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, fill = as.factor(noise_cov_dist)),
color = 'transparent',
fun.min = function(z) { quantile(z,0.25) },
fun.max = function(z) { quantile(z,0.75) },
fun = median,
geom = 'ribbon', alpha = 0.3) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist)),
fun = median,
geom = 'line') +
scale_color_discrete('Spatial autocorrelation of noise') +
scale_fill_discrete('Spatial autocorrelation of noise') +
scale_shape_discrete('Spatial autocorrelation of noise') +
xlab('Noise amplitude') +
ylab('Relative absoulte error') +
theme_bw() +
theme(legend.position = 'bottom')
# some verification of the bias by plotting predicted vs. observed
ggplot(data = data, mapping = aes(x = R_mean, y = x_reduced_mean, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(25, 30)) +
ylim(c(25, 30)) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_sd, y = x_reduced_sd, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(0, 6)) +
ylim(c(0, 6)) +
theme_bw()
ggplot(data = data, mapping = aes(x = R_acf_1, y = x_reduced_acf_1, shape = kind, color = kind)) +
geom_point(alpha = 0.5) +
xlim(c(0, 1)) +
ylim(c(0, 1)) +
theme_bw()
ggsave('RAE_noisy.pdf', width = 210, height = 148, unit = 'mm')
library(ggplot2)
library(reshape2)
data = read.csv('output/0_All_data.csv', header = T)
# computing the relative absolute error of mean, sd and acf_1
data$mean_RAE = abs(data$x_reduced_mean - data$R_mean)/pmax(data$R_mean, data$x_reduced_mean)
data$sd_RAE = abs(data$x_reduced_sd - data$R_sd)/pmax(data$R_sd, data$x_reduced_sd)
data$acf_1_RAE = abs(data$x_reduced_acf_1 - data$R_acf_1)/pmax(abs(data$R_acf_1), abs(data$x_reduced_acf_1))
data_melted = melt(data,
measure.vars = c("mean_RAE", "sd_RAE", "acf_1_RAE"),
variable.name = 'Metric',
value.name = 'Relative_absolute_error')
metric.lab = c('Mean', 'Standard deviation', 'Autocorrelation lag 1')
names(metric.lab) = c('mean_RAE', 'sd_RAE', 'acf_1_RAE')
ggplot(data = data_melted, mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist), shape = as.factor(noise_cov_dist))) +
geom_point(alpha = 0.5) +
facet_grid(Metric ~ kind, labeller = labeller(Metric = metric.lab)) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, fill = as.factor(noise_cov_dist)),
color = 'transparent',
fun.min = function(z) { quantile(z,0.25) },
fun.max = function(z) { quantile(z,0.75) },
fun = median,
geom = 'ribbon', alpha = 0.3) +
stat_summary(
mapping = aes(x = noise_amplitude, y = Relative_absolute_error, color = as.factor(noise_cov_dist)),
fun = median,
geom = 'line') +
scale_color_discrete('Spatial autocorrelation of noise') +
scale_fill_discrete('Spatial autocorrelation of noise') +
scale_shape_discrete('Spatial autocorrelation of noise') +
xlab('Noise amplitude') +
ylab('Relative absoulte error') +
theme_bw() +
theme(legend.position = 'bottom')
ggsave('RAE_noisy.pdf', width = 210, height = 148, unit = 'mm')
